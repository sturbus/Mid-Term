{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "446d3b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23000784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allowed someone to make changes to my account...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy with the netflix time period for transf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i opened a new account on the st march  and on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is ridiculous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if you would like to call me for further infor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 new\n",
       "0   allowed someone to make changes to my account...\n",
       "1   happy with the netflix time period for transf...\n",
       "2  i opened a new account on the st march  and on...\n",
       "3                                this is ridiculous \n",
       "4  if you would like to call me for further infor..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('clean_netflix_comments.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb2513bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('clean_netflix_comments.csv', 'r', encoding='utf8') as file:\n",
    "    text = file.read()\n",
    "    \n",
    "    tokens = text.split()\n",
    "\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "    text = ''.join(word for word in text if not word.isdigit())\n",
    "\n",
    "    text = text.lower()\n",
    "    \n",
    "with open('clean_netflix.csv', 'w',encoding='utf8') as file:\n",
    "    file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c5044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "\n",
    "with open('clean_comments.csv', 'r', encoding='utf8') as file:\n",
    "    text = file.read()\n",
    "    \n",
    "    \n",
    "# create an instance of PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# function to stem text data\n",
    "def stem_text(text):\n",
    "    #removing stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # tokenize the text data\n",
    "    tokens = word_tokenize(text)\n",
    "    # stem each token\n",
    "    stemmed_tokens = [porter_stemmer.stem(token) for token in tokens]\n",
    "    # join the stemmed tokens back into a string\n",
    "    text = ' '.join(stemmed_tokens)\n",
    "    return text\n",
    "\n",
    "# apply the stem_text function to the Cleaned Comment column of the dataframe\n",
    "df['Stemmed Comment'] = df['new'].apply(stem_text)\n",
    "\n",
    "# display a sample of the stemmed data\n",
    "df['Stemmed Comment'].sample(10)\n",
    "\n",
    "#wordcloud = WordCloud(width=700, height=700, background_color='white', stopwords= stop_words, min_font_size=12).generate(stemmed_string)\n",
    "\n",
    "# plot the wordcloud\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "stemmed_text = ' '.join(stemmed_tokens)\n",
    "print( stemmed_text)\n",
    "\n",
    "with open('clean_comments.csv', 'w',encoding='utf8') as file:\n",
    "    file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b78bfe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
